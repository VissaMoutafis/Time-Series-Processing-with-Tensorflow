{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3_C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "1wov8U2Xn-Ma"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wOZefHUoN6N",
        "outputId": "862275d9-aa2c-4f38-c18e-478d15d94834"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dataset_path = 'drive/MyDrive/Collab-Datasets/nasd_input.csv'\n",
        "query_dataset_path = 'drive/MyDrive/Collab-Datasets/nasd_query.csv'\n",
        "DATASET_SIZE = 1\n",
        "LOOKBACK = 15"
      ],
      "metadata": {
        "id": "HAF5jK78oRoG"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df = pd.read_csv(input_dataset_path, sep='\\t', index_col=0, header=None).astype(np.float32).sample(DATASET_SIZE)\n",
        "TIME_SERIES_ID = timeseries_df.index.tolist()"
      ],
      "metadata": {
        "id": "jARNmYaJoUd-"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(X, _max, _min):\n",
        "  return (X - _min)/(_max-_min) \n",
        "\n",
        "def reverse_normalize(X, _max, _min):\n",
        "  return X*(_max-_min) + _min \n",
        "\n",
        "def preprocess_timeseries(_timeseries, window=10, normalized=False, _max = None, _min = None):\n",
        "  if not normalized:\n",
        "    if _max is None:\n",
        "      _max = _timeseries.min()\n",
        "    if _min is None:\n",
        "      _min = _timeseries.max()\n",
        "\n",
        "    timeseries = normalize(_timeseries, _max, _min)\n",
        "  else:\n",
        "    timeseries = _timeseries\n",
        "  \n",
        "  X = None\n",
        "  for i in range(window, len(timeseries)):\n",
        "    X_i = np.asarray(timeseries[i-window:i]).reshape((1, len(timeseries[i-window:i]), 1))\n",
        "    X = np.concatenate((X, X_i)) if X is not None else X_i\n",
        "    \n",
        "  return X, _max, _min"
      ],
      "metadata": {
        "id": "mAptNRCWoXLI"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_length = 15\n",
        "X_all, _max, _min = preprocess_timeseries(timeseries_df.to_numpy()[0], window_length)\n",
        "print(X_all.shape)\n",
        "X_train, X_test = train_test_split(X_all, test_size=0.33)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xbm3R1pDWP",
        "outputId": "d09cb5c9-86f0-425b-dab6-55eafb221447"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(715, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesComplexityReducer():\n",
        "  n_conv_filt_default = 10\n",
        "  def __init__(self, window_size, conv_layers_setting=[], latent_dim=3, batch_size=64, pool_size=2, verbose=False):\n",
        "    self.batch_size = batch_size \n",
        "    self.verbose=verbose\n",
        "    \n",
        "    # init input layer\n",
        "    input_w = layers.Input(shape=(window_size,1))\n",
        "    input_dim = window_size\n",
        "    x = input_w\n",
        "\n",
        "    # add the convolution layers\n",
        "    for conv_settings in conv_layers_setting:\n",
        "      # set up convolution filters and kernel dimensions \n",
        "      filters = self.n_conv_filt_default\n",
        "      if 'filters' in conv_settings:\n",
        "        filters = conv_settings['filters']\n",
        "      kernel_size = conv_settings['kernel_size']\n",
        "\n",
        "      # add the layer into the encoder\n",
        "      x = layers.Conv1D(filters, kernel_size, padding=\"same\", activation=\"relu\")(x)\n",
        "      \n",
        "      # downsample if you can\n",
        "      if ceil(input_dim/pool_size) > latent_dim:\n",
        "        input_dim = ceil(input_dim/pool_size)\n",
        "        x = layers.MaxPooling1D(pool_size, padding=\"same\")(x)\n",
        "\n",
        "    # final compression\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(latent_dim, activation='relu')(x)\n",
        "    encoded = layers.Reshape((latent_dim, 1))(x)\n",
        "    \n",
        "    self.encoder = models.Model(input_w, encoded, name='encoder')\n",
        "    if self.verbose:\n",
        "      self.encoder.summary()    \n",
        "\n",
        "\n",
        "    # decoder model\n",
        "    output_dim = latent_dim \n",
        "\n",
        "    x = layers.Conv1DTranspose(1, latent_dim, activation='relu', padding=\"same\")(encoded)\n",
        "    \n",
        "    if output_dim*pool_size <= window_size:\n",
        "        output_dim = output_dim*pool_size\n",
        "        x = layers.UpSampling1D(pool_size)(x)\n",
        "\n",
        "    for i, conv_settings in enumerate(conv_layers_setting[::-1]):\n",
        "      padding=\"same\"\n",
        "      filters = self.n_conv_filt_default\n",
        "      if 'filters' in conv_settings:\n",
        "        filters = conv_settings['filters']\n",
        "      kernel_size = conv_settings['kernel_size']\n",
        "\n",
        "      x = layers.Conv1DTranspose(filters, kernel_size, activation=\"relu\", padding=padding)(x)\n",
        "      \n",
        "      if output_dim*pool_size <= window_size:\n",
        "        output_dim = output_dim*pool_size\n",
        "        x = layers.UpSampling1D(pool_size)(x)\n",
        "\n",
        "    # decoded = layers.Conv1DTranspose(1, window_size-output_dim+1, activation=\"sigmoid\")(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(window_size, activation='sigmoid')(x)\n",
        "    decoded = layers.Reshape((window_size, 1))(x)\n",
        "\n",
        "    self.autoencoder = models.Model(input_w, decoded, name=\"autoencoder\")\n",
        "    self.autoencoder.summary()\n",
        "    self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "  def fit(self, X, y, epochs=50):\n",
        "    self.history = self.autoencoder.fit(X, y,\n",
        "                epochs=epochs,\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=True,\n",
        "                validation_split=0.3, \n",
        "                verbose=self.verbose)\n",
        "    return self.history\n",
        "  def predict(self, X):\n",
        "    return self.autoencoder.predict(X)"
      ],
      "metadata": {
        "id": "NuVmfa77O56r"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = TimeSeriesComplexityReducer(window_length, [{'filters':20, 'kernel_size':5}, {'filters':10, 'kernel_size':5}, {'filters':5, 'kernel_size':3}], latent_dim=10, verbose=True, pool_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Coq-aTnYR7S",
        "outputId": "28e15306-7229-4a86-dcf7-1ef163ccbcac"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_83 (InputLayer)       [(None, 15, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_391 (Conv1D)         (None, 15, 20)            120       \n",
            "                                                                 \n",
            " conv1d_392 (Conv1D)         (None, 15, 10)            1010      \n",
            "                                                                 \n",
            " conv1d_393 (Conv1D)         (None, 15, 5)             155       \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 75)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                760       \n",
            "                                                                 \n",
            " reshape_20 (Reshape)        (None, 10, 1)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,045\n",
            "Trainable params: 2,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_83 (InputLayer)       [(None, 15, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_391 (Conv1D)         (None, 15, 20)            120       \n",
            "                                                                 \n",
            " conv1d_392 (Conv1D)         (None, 15, 10)            1010      \n",
            "                                                                 \n",
            " conv1d_393 (Conv1D)         (None, 15, 5)             155       \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 75)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                760       \n",
            "                                                                 \n",
            " reshape_20 (Reshape)        (None, 10, 1)             0         \n",
            "                                                                 \n",
            " conv1d_transpose_94 (Conv1D  (None, 10, 1)            11        \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv1d_transpose_95 (Conv1D  (None, 10, 5)            20        \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv1d_transpose_96 (Conv1D  (None, 10, 10)           260       \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv1d_transpose_97 (Conv1D  (None, 10, 20)           1020      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 15)                3015      \n",
            "                                                                 \n",
            " reshape_21 (Reshape)        (None, 15, 1)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,371\n",
            "Trainable params: 6,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(X_train, X_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Avz7i8QiJ6c",
        "outputId": "ff350a48-3bb2-4e2f-8038-a896dfae00ad"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 71ms/step - loss: 0.6910 - val_loss: 0.6867\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6821 - val_loss: 0.6727\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6632 - val_loss: 0.6455\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6292 - val_loss: 0.6037\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5862 - val_loss: 0.5837\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5850 - val_loss: 0.5863\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5763 - val_loss: 0.5771\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5739 - val_loss: 0.5782\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5732 - val_loss: 0.5748\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5715 - val_loss: 0.5740\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5704 - val_loss: 0.5716\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5688 - val_loss: 0.5698\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5673 - val_loss: 0.5677\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.5661 - val_loss: 0.5656\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5647 - val_loss: 0.5635\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5633 - val_loss: 0.5613\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5617 - val_loss: 0.5588\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5604 - val_loss: 0.5562\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5583 - val_loss: 0.5541\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5560 - val_loss: 0.5497\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5530 - val_loss: 0.5460\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5498 - val_loss: 0.5425\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5470 - val_loss: 0.5394\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5446 - val_loss: 0.5368\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5424 - val_loss: 0.5350\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5411 - val_loss: 0.5339\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5404 - val_loss: 0.5334\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5400 - val_loss: 0.5332\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5398 - val_loss: 0.5325\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5395 - val_loss: 0.5323\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5394 - val_loss: 0.5322\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5392 - val_loss: 0.5319\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5391 - val_loss: 0.5317\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5390 - val_loss: 0.5315\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5388 - val_loss: 0.5313\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5387 - val_loss: 0.5311\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5385 - val_loss: 0.5308\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5384 - val_loss: 0.5304\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5382 - val_loss: 0.5300\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5380 - val_loss: 0.5295\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5377 - val_loss: 0.5290\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5375 - val_loss: 0.5285\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5373 - val_loss: 0.5281\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5371 - val_loss: 0.5272\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5366 - val_loss: 0.5265\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5363 - val_loss: 0.5256\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5359 - val_loss: 0.5249\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5357 - val_loss: 0.5243\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5355 - val_loss: 0.5237\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5353 - val_loss: 0.5229\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5351 - val_loss: 0.5226\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5350 - val_loss: 0.5223\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5349 - val_loss: 0.5218\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5347 - val_loss: 0.5215\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5345 - val_loss: 0.5213\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5343 - val_loss: 0.5209\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5341 - val_loss: 0.5208\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5341 - val_loss: 0.5203\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5340 - val_loss: 0.5203\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5338 - val_loss: 0.5199\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5337 - val_loss: 0.5196\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5335 - val_loss: 0.5194\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5334 - val_loss: 0.5192\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5333 - val_loss: 0.5189\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5334 - val_loss: 0.5190\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.5333 - val_loss: 0.5188\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5332 - val_loss: 0.5190\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5333 - val_loss: 0.5187\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5331 - val_loss: 0.5183\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5329 - val_loss: 0.5181\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5328 - val_loss: 0.5181\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5328 - val_loss: 0.5180\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5327 - val_loss: 0.5181\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5327 - val_loss: 0.5180\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5327 - val_loss: 0.5179\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5327 - val_loss: 0.5178\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5326 - val_loss: 0.5179\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5326 - val_loss: 0.5178\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5326 - val_loss: 0.5178\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5326 - val_loss: 0.5178\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5326 - val_loss: 0.5178\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5325 - val_loss: 0.5177\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5325 - val_loss: 0.5177\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5325 - val_loss: 0.5177\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5325 - val_loss: 0.5177\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.5325 - val_loss: 0.5177\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5325 - val_loss: 0.5178\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5325 - val_loss: 0.5176\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5324 - val_loss: 0.5177\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5324 - val_loss: 0.5177\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5324 - val_loss: 0.5179\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5325 - val_loss: 0.5178\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5324 - val_loss: 0.5179\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5324 - val_loss: 0.5179\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5323 - val_loss: 0.5178\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5323 - val_loss: 0.5178\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5323 - val_loss: 0.5177\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5323 - val_loss: 0.5176\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5323 - val_loss: 0.5177\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5323 - val_loss: 0.5176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ab87e35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(stock_input, stock_decoded):\n",
        "    n = 10  \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, idx in enumerate(list(np.arange(0, test_samples, 200))):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        if i == 0:\n",
        "            ax.set_ylabel(\"Input\", fontweight=600)\n",
        "        else:\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "        plt.plot(stock_input[idx])\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        \n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        if i == 0:\n",
        "            ax.set_ylabel(\"Output\", fontweight=600)\n",
        "        else:\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "        plt.plot(stock_decoded[idx])\n",
        "        ax.get_xaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "TOaFYVA9ptRb"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = 50\n",
        "\n",
        "plot_examples(reverse_normalize(X_test, _max, _min), reverse_normalize(autoencoder.predict(X_test), _max, _min))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "MfMbWQbYseyI",
        "outputId": "36cdd046-5fea-4031-950e-cf0fc736bbd8"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.predict(X_test).shape"
      ],
      "metadata": {
        "id": "Pvk7ZIJ0yHmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9fe2ef-3fec-41c7-d42a-5e2cce1aa7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NlECVIcv8nO",
        "outputId": "0799b252-3e74-4617-e623-709c51e761a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UwxP0bX4v-x5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}