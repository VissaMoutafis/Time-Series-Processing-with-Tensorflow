{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3_C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "1wov8U2Xn-Ma"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wOZefHUoN6N",
        "outputId": "2676a5a6-3c6a-442c-f94e-f66474d805e3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dataset_path = 'drive/MyDrive/Collab-Datasets/nasd_input.csv'\n",
        "query_dataset_path = 'drive/MyDrive/Collab-Datasets/nasd_query.csv'\n",
        "DATASET_SIZE = 1\n",
        "LOOKBACK = 10"
      ],
      "metadata": {
        "id": "HAF5jK78oRoG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df = pd.read_csv(input_dataset_path, sep='\\t', index_col=0, header=None).astype(np.float32).sample(DATASET_SIZE)\n",
        "TIME_SERIES_ID = timeseries_df.index.tolist()"
      ],
      "metadata": {
        "id": "jARNmYaJoUd-"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(X, _max, _min):\n",
        "  return (X - _max)/(_min-_max) \n",
        "\n",
        "def reverse_normalize(X, _max, _min):\n",
        "  return X*(_min-_max) + _max \n",
        "\n",
        "def preprocess_timeseries(_timeseries, window=10, normalized=False, _max = None, _min = None):\n",
        "  if not normalized:\n",
        "    if _max is None:\n",
        "      _max = _timeseries.min()\n",
        "    if _min is None:\n",
        "      _min = _timeseries.max()\n",
        "\n",
        "    timeseries = normalize(_timeseries, _max, _min)\n",
        "  else:\n",
        "    timeseries = _timeseries\n",
        "  \n",
        "  X = None\n",
        "  for i in range(window, len(timeseries)):\n",
        "    X_i = np.asarray(timeseries[i-window:i]).reshape((1, len(timeseries[i-window:i]), 1))\n",
        "    X = np.concatenate((X, X_i)) if X is not None else X_i\n",
        "    \n",
        "  return X, _max, _min"
      ],
      "metadata": {
        "id": "mAptNRCWoXLI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_length = 10\n",
        "X_all, _max, _min = preprocess_timeseries(timeseries_df.to_numpy()[0], window_length)\n",
        "print(X_all.shape)\n",
        "X_train, X_test = train_test_split(X_all, test_size=0.33)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xbm3R1pDWP",
        "outputId": "a1cabc74-6fc7-450a-87c4-9c8031820c67"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesComplexityReducer():\n",
        "  n_conv_filt_default = 10\n",
        "  def __init__(self, window_size, conv_layers_setting=[], latent_dim=3, batch_size=64, pool_size=2, verbose=False):\n",
        "    self.batch_size = batch_size \n",
        "    self.verbose=verbose\n",
        "    \n",
        "    input_w = layers.Input(shape=(window_size,1))\n",
        "    input_dim = window_size\n",
        "    x = input_w\n",
        "    for conv_settings in conv_layers_setting:\n",
        "      filters = self.n_conv_filt_default\n",
        "      if 'filters' in conv_settings:\n",
        "        filters = conv_settings['filters']\n",
        "      kernel_size = conv_settings['kernel_size']\n",
        "      x = layers.Conv1D(filters, kernel_size, padding=\"same\", activation=\"relu\")(x)\n",
        "      if ceil(input_dim/pool_size) > latent_dim:\n",
        "        input_dim = ceil(input_dim/pool_size)\n",
        "        x = layers.MaxPooling1D(pool_size, padding=\"same\")(x)\n",
        "\n",
        "    # final compression\n",
        "    compressor_filters = ceil(input_dim / latent_dim)\n",
        "    compressor_kernel_space = input_dim-latent_dim*compressor_filters + 1\n",
        "    if compressor_kernel_space > 0:\n",
        "      x = layers.Conv1D(1, compressor_kernel_space, activation=\"relu\")(x)\n",
        "      encoded = layers.MaxPooling1D(compressor_filters, padding=\"same\")(x)\n",
        "    elif compressor_kernel_space < 0:\n",
        "      compressor_kernel_space = input_dim-latent_dim+1\n",
        "      encoded = layers.Conv1D(1, input_dim-latent_dim+1, activation=\"relu\")(x)\n",
        "    else:\n",
        "      compressor_kernel_space = latent_dim\n",
        "      x = layers.Conv1D(1, compressor_kernel_space, activation=\"relu\", padding=\"same\")(x)\n",
        "      encoded = layers.MaxPooling1D(compressor_filters, padding=\"same\")(x)\n",
        "    \n",
        "    self.encoder = models.Model(input_w, encoded, name='encoder')\n",
        "    if self.verbose:\n",
        "      self.encoder.summary()    \n",
        "\n",
        "    # decoder model\n",
        "    output_dim = latent_dim \n",
        "\n",
        "    x = layers.Conv1D(1, compressor_kernel_space, activation='relu', padding=\"same\")(encoded)\n",
        "    if output_dim*pool_size <= window_size:\n",
        "        output_dim = output_dim*pool_size\n",
        "        x = layers.UpSampling1D(pool_size)(x)\n",
        "\n",
        "    for i, conv_settings in enumerate(conv_layers_setting[::-1]):\n",
        "      padding=\"same\"\n",
        "      filters = self.n_conv_filt_default\n",
        "      if 'filters' in conv_settings:\n",
        "        filters = conv_settings['filters']\n",
        "      kernel_size = conv_settings['kernel_size']\n",
        "      \n",
        "      if i == len(conv_layers_setting)-1:\n",
        "        # we must treat the final layer differently\n",
        "        if window_size % pool_size == 0:\n",
        "          kernel_size = int(output_dim - window_size//pool_size + 1)\n",
        "          output_dim = window_size//pool_size\n",
        "          padding=\"valid\"\n",
        "\n",
        "      x = layers.Conv1D(filters, kernel_size, activation=\"relu\", padding=padding)(x)\n",
        "      \n",
        "      if output_dim*pool_size <= window_size:\n",
        "        output_dim = output_dim*pool_size\n",
        "        x = layers.UpSampling1D(pool_size)(x)\n",
        "\n",
        "    decoded = layers.Conv1D(1, latent_dim, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    self.autoencoder = models.Model(input_w, decoded, name=\"autoencoder\")\n",
        "    self.autoencoder.summary()\n",
        "    self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "  def fit(self, X, y, epochs=50):\n",
        "    self.history = self.autoencoder.fit(X, y,\n",
        "                epochs=epochs,\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=True,\n",
        "                validation_split=0.3, \n",
        "                verbose=self.verbose)\n",
        "    return self.history\n",
        "  def predict(self, X):\n",
        "    return self.autoencoder.predict(X)"
      ],
      "metadata": {
        "id": "NuVmfa77O56r"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = TimeSeriesComplexityReducer(10, [{'filters':16, 'kernel_size':5}, {'filters':16, 'kernel_size':5}], latent_dim=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Coq-aTnYR7S",
        "outputId": "ab365bce-acb1-4ac3-b5e6-1a66a577bbcf"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 10, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_112 (Conv1D)         (None, 10, 16)            96        \n",
            "                                                                 \n",
            " conv1d_113 (Conv1D)         (None, 10, 16)            1296      \n",
            "                                                                 \n",
            " conv1d_114 (Conv1D)         (None, 10, 1)             17        \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 5, 1)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,409\n",
            "Trainable params: 1,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 10, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_112 (Conv1D)         (None, 10, 16)            96        \n",
            "                                                                 \n",
            " conv1d_113 (Conv1D)         (None, 10, 16)            1296      \n",
            "                                                                 \n",
            " conv1d_114 (Conv1D)         (None, 10, 1)             17        \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 5, 1)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_115 (Conv1D)         (None, 5, 1)              2         \n",
            "                                                                 \n",
            " up_sampling1d_33 (UpSamplin  (None, 10, 1)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_116 (Conv1D)         (None, 10, 16)            96        \n",
            "                                                                 \n",
            " conv1d_117 (Conv1D)         (None, 5, 16)             1552      \n",
            "                                                                 \n",
            " up_sampling1d_34 (UpSamplin  (None, 10, 16)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_118 (Conv1D)         (None, 10, 1)             81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,140\n",
            "Trainable params: 3,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(X_train, X_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Avz7i8QiJ6c",
        "outputId": "aacee7a0-c83c-4bc5-f382-fb36672f56ee"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 1s 59ms/step - loss: 0.6867 - val_loss: 0.6740\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6663 - val_loss: 0.6457\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6342 - val_loss: 0.6057\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5883 - val_loss: 0.5514\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5289 - val_loss: 0.4917\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4721 - val_loss: 0.4500\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4433 - val_loss: 0.4359\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4347 - val_loss: 0.4300\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4303 - val_loss: 0.4266\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4255 - val_loss: 0.4216\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4202 - val_loss: 0.4169\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4145 - val_loss: 0.4129\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4098 - val_loss: 0.4093\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4056 - val_loss: 0.4073\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4031 - val_loss: 0.4056\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4013 - val_loss: 0.4047\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4001 - val_loss: 0.4039\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3992 - val_loss: 0.4032\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3983 - val_loss: 0.4024\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3974 - val_loss: 0.4017\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3963 - val_loss: 0.4011\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3955 - val_loss: 0.4008\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3948 - val_loss: 0.4004\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3940 - val_loss: 0.4001\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3934 - val_loss: 0.3992\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3929 - val_loss: 0.3991\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3920 - val_loss: 0.3989\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3911 - val_loss: 0.3983\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3905 - val_loss: 0.3979\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3900 - val_loss: 0.3980\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3896 - val_loss: 0.3975\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3891 - val_loss: 0.3977\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3888 - val_loss: 0.3970\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3883 - val_loss: 0.3970\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3878 - val_loss: 0.3966\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3874 - val_loss: 0.3965\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3871 - val_loss: 0.3968\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3868 - val_loss: 0.3962\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3865 - val_loss: 0.3964\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3864 - val_loss: 0.3959\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3860 - val_loss: 0.3958\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3857 - val_loss: 0.3959\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3855 - val_loss: 0.3955\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3853 - val_loss: 0.3953\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3852 - val_loss: 0.3955\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3851 - val_loss: 0.3952\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3848 - val_loss: 0.3951\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3847 - val_loss: 0.3951\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3846 - val_loss: 0.3954\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3845 - val_loss: 0.3947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c1b7a0610>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(stock_input, stock_decoded):\n",
        "    n = 10  \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, idx in enumerate(list(np.arange(0, test_samples, 200))):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        if i == 0:\n",
        "            ax.set_ylabel(\"Input\", fontweight=600)\n",
        "        else:\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "        plt.plot(stock_input[idx])\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        \n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        if i == 0:\n",
        "            ax.set_ylabel(\"Output\", fontweight=600)\n",
        "        else:\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "        plt.plot(stock_decoded[idx])\n",
        "        ax.get_xaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "TOaFYVA9ptRb"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = 100\n",
        "\n",
        "plot_examples(reverse_normalize(X_test, _max, _min), reverse_normalize(autoencoder.predict(X_test), _max, _min))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "MfMbWQbYseyI",
        "outputId": "f616bf0f-7a7f-4631-b389-ef2b3c34093b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.predict(X_test).shape"
      ],
      "metadata": {
        "id": "Pvk7ZIJ0yHmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9fe2ef-3fec-41c7-d42a-5e2cce1aa7a2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NlECVIcv8nO",
        "outputId": "0799b252-3e74-4617-e623-709c51e761a0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UwxP0bX4v-x5"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}